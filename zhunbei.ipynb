{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a3e0d1-ee03-4e71-9ec5-ca0262dcb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e14604-bbde-4e4f-9536-fae6f569d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145317bb-2d87-4a01-a279-5402fa78c9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22912/22912 [00:03<00:00, 5959.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(csv))):\n",
    "    directory = 'data/train/'+str(csv.iloc[i][1])\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    shutil.move('data/train/'+csv.iloc[i][0],directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "428fe7eb-0873-4b3d-a40e-3e2983963950",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r data data-nong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6ec45-7940-4554-9a4b-feac729fb602",
   "metadata": {},
   "source": [
    "## 增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2626cf91-600e-443b-934c-7625c0de81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(src):\n",
    "    # 定义增广方法,需要根据任务以及图像适当做调整\n",
    "    trains_list = [\n",
    "        transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=1),\n",
    "            transforms.ToTensor(),\n",
    "    ]),\n",
    "        transforms.Compose([\n",
    "            transforms.RandomVerticalFlip(p=1),\n",
    "                transforms.ToTensor(),\n",
    "    ]),\n",
    "        transforms.Compose([\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ToTensor(),\n",
    "    ]),\n",
    "        transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.2, hue=0.3),  # 随机调整亮度，对比度，饱和度和色相\n",
    "            transforms.ToTensor(),\n",
    "    ]),\n",
    "    #     transforms.Compose([\n",
    "    #         transforms.ToTensor(),\n",
    "    #         transforms.RandomErasing(p=1, scale=(0.02, 0.1), ratio=(0.3, 0.3), value=(0, 0, 0)),\n",
    "    # ]),\n",
    "    #     transforms.Compose([\n",
    "    #         transforms.Resize((1024, 1024)),\n",
    "    #         transforms.RandomCrop(size=512, padding=0, pad_if_needed=False, fill=0, padding_mode='constant'),\n",
    "    #         transforms.ToTensor(),\n",
    "    # ])\n",
    "    ]\n",
    "    all_items = os.listdir(src) #data/train/\n",
    "\n",
    "    for h in tqdm(range(len(all_items))):\n",
    "        data_dir = src + all_items[h]\n",
    "        imgs_names = glob.glob(data_dir + '/*.jpg')\n",
    "        count = 0\n",
    "        for i in range(len(imgs_names)):\n",
    "            image = Image.open(imgs_names[i]).convert('RGB')\n",
    "            for trans in trains_list:\n",
    "                aug_image = trans(image)\n",
    "                count += 1\n",
    "                filename = f'{all_items[h]}_image_{count}.jpg'\n",
    "                save_path = os.path.join(\"data/train/\"+all_items[h], filename)\n",
    "                aug_image_pil = transforms.ToPILImage()(aug_image)\n",
    "                aug_image_pil.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4add4531-e142-4924-a529-ced3f0f69ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "normal(\"data-nong/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364efb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机擦除\n",
    "def random_erase(img,n_holes,length,rate): #输入img为PIL图片格式的图片\n",
    "    if np.random.rand(1)[0]<rate:\n",
    "        img = np.array(img)\n",
    "        h = img.shape[0] #图片的高\n",
    "        w = img.shape[1] #图片的宽\n",
    "        \n",
    "        n_holes = np.random.randint(n_holes)\n",
    "        mask = np.ones((h, w), np.float32) #32*32w*h的全1矩阵\n",
    "\n",
    "        for n in range(n_holes): #n_holes=2,length=4 选择2个区域；每个区域的边长为4\n",
    "            y = np.random.randint(h) #0~31随机选择一个数 y=4\n",
    "            x = np.random.randint(w) #0~31随机选择一个数 x=24\n",
    "\n",
    "            y1 = np.clip(y - length // 2, 0, h) #2,0,32 ->2\n",
    "            y2 = np.clip(y + length // 2, 0, h) #6,0,32 ->6\n",
    "            x1 = np.clip(x - length // 2, 0, w) #24-2,0,32 ->22\n",
    "            x2 = np.clip(x + length // 2, 0, w) #24+2,0,32 ->26\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0. #将这一小块区域去除\n",
    "        img[:,:,0] = img[:,:,0] * mask\n",
    "        img[:,:,1] = img[:,:,1] * mask\n",
    "        img[:,:,2] = img[:,:,2] * mask\n",
    "        return Image.fromarray(img)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92dbc0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:24<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "all_items = os.listdir('data-nong/train')\n",
    "for i in tqdm(range(len(all_items))):\n",
    "        data_dir = 'data-nong/train/' + all_items[i]\n",
    "        imgs_names = glob.glob(data_dir + '/*.jpg')\n",
    "        count = 0\n",
    "        for j in range(len(imgs_names)):\n",
    "            img = Image.open(imgs_names[j]).convert('RGB')\n",
    "            img2 = random_erase(img,150,3,1)\n",
    "            count += 1\n",
    "            img2.save(\"data/train/\"+all_items[i]+\"/erase\"+str(count)+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067d4b3-152c-4f01-a91a-e5aca79807f6",
   "metadata": {},
   "source": [
    "## 为标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "341371aa-c191-4387-bb2a-433d7aeba816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6165/6165 [00:02<00:00, 2343.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# csv1 = pd.read_csv('1.csv')\n",
    "# for i in tqdm(range(len(csv1))):\n",
    "#     shutil.copy('data/test/'+csv1.iloc[i][0],'data/train/'+str(csv1.iloc[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ca4e0a-acd1-4ab2-875d-801eab5c04d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mistgpu/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n",
      "  model = create_fn(\n",
      "100%|██████████| 6165/6165 [06:58<00:00, 14.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_pre_img = pd.Series(glob.glob('data/test/*'))\n",
    "path_pre_img = path_pre_img.apply(lambda x:x.split('/')[2]).tolist()\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test3 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.2, hue=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test4 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomVerticalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "list_trans = [transform_test,transform_test1,transform_test2,transform_test3,transform_test4]\n",
    "# model = SVHN_Model2().cuda()\n",
    "import timm\n",
    "model = timm.create_model('convnext_small_in22k', pretrained=True,num_classes=25).cuda()\n",
    "model.load_state_dict(torch.load(\"best_model-3.pth\"))\n",
    "\n",
    "classes=['0','1','10','11','12','13','14','15','16','17','18','19','2','20','21','22','23','24','3','4','5','6','7','8','9']\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "path='data/test/'\n",
    "for i in tqdm(range(len(path_pre_img))):\n",
    "    for j in range(len(list_trans)):\n",
    "        img=Image.open(path+path_pre_img[i])\n",
    "        img=img.convert('RGB')\n",
    "        img=list_trans[j](img)\n",
    "        img.unsqueeze_(0)\n",
    "        img = Variable(img).to(DEVICE)\n",
    "        if j==0:\n",
    "            out=model(img)\n",
    "        else:\n",
    "            out+=model(img)\n",
    "    img=Image.open(path+path_pre_img[i])\n",
    "    img=img.convert('RGB')\n",
    "    img=random_erase(img,150,3,1)\n",
    "    img=transform_test(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = Variable(img).to(DEVICE)\n",
    "    out+=model(img)\n",
    "    probs = torch.nn.functional.softmax(out, dim=-1)\n",
    "    confidence, predicted_class = torch.max(probs, 1)\n",
    "    confidence = confidence.item()\n",
    "    _, pred = torch.max(out.data, 1)\n",
    "    if confidence > 0.9:\n",
    "        shutil.copy('data/test/'+path_pre_img[i],'data/train/'+classes[pred.data.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b379b-e808-4f0f-aeeb-4aa1595c23b8",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ca258a-1683-4634-b2a2-971b38fd368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import timm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_pre_img = pd.Series(glob.glob('data/test/*'))\n",
    "path_pre_img = path_pre_img.apply(lambda x:x.split('/')[2]).tolist()\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test3 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.2, hue=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "list_trans = [transform_test,transform_test1,transform_test2,transform_test3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55eb073a-a5a3-46ec-8a4c-9cf5051e72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机擦除\n",
    "def random_erase(img,n_holes,length,rate): #输入img为PIL图片格式的图片\n",
    "    if np.random.rand(1)[0]<rate:\n",
    "        img = np.array(img)\n",
    "        h = img.shape[0] #图片的高\n",
    "        w = img.shape[1] #图片的宽\n",
    "        \n",
    "        n_holes = np.random.randint(n_holes)\n",
    "        mask = np.ones((h, w), np.float32) #32*32w*h的全1矩阵\n",
    "\n",
    "        for n in range(n_holes): #n_holes=2,length=4 选择2个区域；每个区域的边长为4\n",
    "            y = np.random.randint(h) #0~31随机选择一个数 y=4\n",
    "            x = np.random.randint(w) #0~31随机选择一个数 x=24\n",
    "\n",
    "            y1 = np.clip(y - length // 2, 0, h) #2,0,32 ->2\n",
    "            y2 = np.clip(y + length // 2, 0, h) #6,0,32 ->6\n",
    "            x1 = np.clip(x - length // 2, 0, w) #24-2,0,32 ->22\n",
    "            x2 = np.clip(x + length // 2, 0, w) #24+2,0,32 ->26\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0. #将这一小块区域去除\n",
    "        img[:,:,0] = img[:,:,0] * mask\n",
    "        img[:,:,1] = img[:,:,1] * mask\n",
    "        img[:,:,2] = img[:,:,2] * mask\n",
    "        return Image.fromarray(img)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e22c1d5-b6f3-4f7d-9b25-50bccb785ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6165/6165 [05:35<00:00, 18.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# model = SVHN_Model2().cuda()\n",
    "import timm\n",
    "model = timm.create_model('convnext_small_in22k', pretrained=True,num_classes=25).cuda()\n",
    "model.load_state_dict(torch.load(\"weights/best_model-3.pth\"))\n",
    "\n",
    "classes=['0','1','10','11','12','13','14','15','16','17','18','19','2','20','21','22','23','24','3','4','5','6','7','8','9']\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "path='data/test/'\n",
    "pre_data =[]\n",
    "pre_label=[]\n",
    "for i in tqdm(range(len(path_pre_img))):\n",
    "    for j in range(len(list_trans)):\n",
    "        img=Image.open(path+path_pre_img[i])\n",
    "        img=img.convert('RGB')\n",
    "        img=list_trans[j](img)\n",
    "        img.unsqueeze_(0)\n",
    "        img = Variable(img).to(DEVICE)\n",
    "        if j==0:\n",
    "            out=model(img)\n",
    "        else:\n",
    "            out+=model(img)\n",
    "    # Predict\n",
    "    img=Image.open(path+path_pre_img[i])\n",
    "    img=img.convert('RGB')\n",
    "    img=random_erase(img,150,3,1)\n",
    "    img=transform_test(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = Variable(img).to(DEVICE)\n",
    "    out+=model(img)\n",
    "    _, pred = torch.max(out.data, 1)\n",
    "    pre_data.append(path_pre_img[i])\n",
    "    pre_label.append(classes[pred.data.item()])\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['name'] = pre_data\n",
    "sub['label'] = pre_label\n",
    "sub.to_csv('./pre_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cacce-82fa-448a-8f51-787b2cd8a9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
